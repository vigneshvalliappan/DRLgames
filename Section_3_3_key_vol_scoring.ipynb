{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section_3_3_key_vol_scoring.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vigneshvalliappan/DRLgames/blob/master/Section_3_3_key_vol_scoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al-dQYYutBo8",
        "outputId": "f2e5bbaf-98cd-4582-abd5-c668dad421d2"
      },
      "source": [
        "# import relevant libraries\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmzpT6579LWv",
        "outputId": "86c16fb4-70e3-4e8c-e8ae-23016077d759"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_cit98XR5HOg",
        "outputId": "1361617d-dd87-4957-a85c-f28c93df8fc6"
      },
      "source": [
        "# read data\n",
        "training_data = pd.read_csv('/content/drive/MyDrive/non DL NLP/Project/training_data_set_v3.csv')\n",
        "\n",
        "training_data = training_data.drop('Unnamed: 0', axis = 1)\n",
        "\n",
        "training_data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EqkT4qw4acnPDE0Ml8Dfog</td>\n",
              "      <td>Xg98DhTV0z4yNiC4LChDtQ</td>\n",
              "      <td>7z2x16M7IuG8KPfMsyVrKA</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>First time visit and it was truly amazing. Eve...</td>\n",
              "      <td>2016-01-30 05:50:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XCRmpw4z8eKLmi1z5wEE4A</td>\n",
              "      <td>5sc03tSvJ10EhK-JGKhdZw</td>\n",
              "      <td>7z2x16M7IuG8KPfMsyVrKA</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>This is my favorite restaurant in Pittsburgh, ...</td>\n",
              "      <td>2017-05-13 13:30:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-kaduqAoh_hFbtH7fTUCYw</td>\n",
              "      <td>FLuZBFZVoh-lWhBd3S3i0w</td>\n",
              "      <td>7z2x16M7IuG8KPfMsyVrKA</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Service was lovely.  I live in NYC and have ea...</td>\n",
              "      <td>2018-09-03 03:27:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>msJzFFkCGmk_JX8o8lXEfA</td>\n",
              "      <td>JAIa7M6Usdt9-LsJDjE8sg</td>\n",
              "      <td>7z2x16M7IuG8KPfMsyVrKA</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Great food and even better atmosphere. Try at ...</td>\n",
              "      <td>2017-01-27 20:43:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>zUujjVzj5X97FEhYMyqR6A</td>\n",
              "      <td>z57vv7gw5cZV1JxHSV6Nvg</td>\n",
              "      <td>7z2x16M7IuG8KPfMsyVrKA</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Absolute fantastic dinner!! My partner and I c...</td>\n",
              "      <td>2017-07-28 20:40:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60242</th>\n",
              "      <td>w8hkeVnfNu3hPiUT4YHdfg</td>\n",
              "      <td>bLbSNkLggFnqwNNzzq-Ijw</td>\n",
              "      <td>slUn4AINGy3QmDK62YGzoA</td>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>I'm in the Chinatown area often but there are ...</td>\n",
              "      <td>2019-04-29 16:18:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60243</th>\n",
              "      <td>Vh8lu4ddh4zXvvjykxOdoQ</td>\n",
              "      <td>9-YU-svmnMfKs_DkcZc0Tg</td>\n",
              "      <td>slUn4AINGy3QmDK62YGzoA</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Location: Las Vegas Chinatown (Jones &amp; Spring ...</td>\n",
              "      <td>2019-10-29 13:58:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60244</th>\n",
              "      <td>CZWxvsTA0uy34qVj9zNyEQ</td>\n",
              "      <td>aWDd4vJtY5uOA9euq7VACg</td>\n",
              "      <td>slUn4AINGy3QmDK62YGzoA</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The place is upscale feeling for a Chinese foo...</td>\n",
              "      <td>2019-11-18 08:46:48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60245</th>\n",
              "      <td>_FhR5ewN_vDbLi6smfIqGA</td>\n",
              "      <td>SyyYQfNQ4a4Lua5RBlggmQ</td>\n",
              "      <td>slUn4AINGy3QmDK62YGzoA</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Been coming here since it was mamajias.  Ummmm...</td>\n",
              "      <td>2019-11-09 02:48:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60246</th>\n",
              "      <td>bhxUg7xNvn8IZzteFnFN3g</td>\n",
              "      <td>aVuKrNrStDlm_JPigliLeQ</td>\n",
              "      <td>slUn4AINGy3QmDK62YGzoA</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>Amazing Chinese restaurant! \\nI've been needin...</td>\n",
              "      <td>2019-10-05 23:43:45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60247 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    review_id  ...                 date\n",
              "0      EqkT4qw4acnPDE0Ml8Dfog  ...  2016-01-30 05:50:59\n",
              "1      XCRmpw4z8eKLmi1z5wEE4A  ...  2017-05-13 13:30:44\n",
              "2      -kaduqAoh_hFbtH7fTUCYw  ...  2018-09-03 03:27:35\n",
              "3      msJzFFkCGmk_JX8o8lXEfA  ...  2017-01-27 20:43:47\n",
              "4      zUujjVzj5X97FEhYMyqR6A  ...  2017-07-28 20:40:33\n",
              "...                       ...  ...                  ...\n",
              "60242  w8hkeVnfNu3hPiUT4YHdfg  ...  2019-04-29 16:18:12\n",
              "60243  Vh8lu4ddh4zXvvjykxOdoQ  ...  2019-10-29 13:58:46\n",
              "60244  CZWxvsTA0uy34qVj9zNyEQ  ...  2019-11-18 08:46:48\n",
              "60245  _FhR5ewN_vDbLi6smfIqGA  ...  2019-11-09 02:48:10\n",
              "60246  bhxUg7xNvn8IZzteFnFN3g  ...  2019-10-05 23:43:45\n",
              "\n",
              "[60247 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOjpa97r4OjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbda8946-83b5-456c-cf4a-8ef5f35d7e6e"
      },
      "source": [
        "# create tokens and associated metrics\n",
        "\n",
        "tokens = pd.DataFrame()\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "tokens['tokenized_minus_stop'] = training_data['text'].apply(lambda x: [tokens.lower() for tokens in word_tokenize(x) if tokens.lower() not in stop_words])\n",
        "tokens['token_vol_no_stop'] = tokens['tokenized_minus_stop'].apply(lambda y: len(y))\n",
        "\n",
        "token_volume_per = [np.percentile(tokens['token_vol_no_stop'], i) for i in range(0, 101, 1)]\n",
        "\n",
        "print(tokens)\n",
        "\n",
        "print('min_token_volume:', min(tokens['token_vol_no_stop']))\n",
        "print('max_token_volume:', max(tokens['token_vol_no_stop']))\n",
        "print()\n",
        "\n",
        "print('0th percentile of token_vol_no_stop:', token_volume_per[0])\n",
        "print('10th percentile of token_vol_no_stop:', token_volume_per[10])\n",
        "print('20th percentile of token_vol_no_stop:', token_volume_per[20])\n",
        "print('30th percentile of token_vol_no_stop:', token_volume_per[30])\n",
        "print('40th percentile of token_vol_no_stop:', token_volume_per[40])\n",
        "print('50th percentile of token_vol_no_stop:', token_volume_per[50])\n",
        "print('60th percentile of token_vol_no_stop:', token_volume_per[60])\n",
        "print('70th percentile of token_vol_no_stop:', token_volume_per[70])\n",
        "print('80th percentile of token_vol_no_stop:', token_volume_per[80])\n",
        "print('90th percentile of token_vol_no_stop:', token_volume_per[90])\n",
        "print('100th percentile of token_vol_no_stop:', token_volume_per[100])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                    tokenized_minus_stop  token_vol_no_stop\n",
            "0      [first, time, visit, truly, amazing, ., every,...                 26\n",
            "1      [favorite, restaurant, pittsburgh, ,, anywhere...                 77\n",
            "2      [service, lovely, ., live, nyc, eaten, spanish...                 64\n",
            "3      [great, food, even, better, atmosphere, ., try...                 17\n",
            "4      [absolute, fantastic, dinner, !, !, partner, c...                203\n",
            "...                                                  ...                ...\n",
            "60242  ['m, chinatown, area, often, many, restaurants...                104\n",
            "60243  [location, :, las, vegas, chinatown, (, jones,...                 54\n",
            "60244  [place, upscale, feeling, chinese, food, joint...                 46\n",
            "60245  [coming, since, mamajias, ., ummmm, sure, 4.5,...                 72\n",
            "60246  [amazing, chinese, restaurant, !, 've, needing...                 97\n",
            "\n",
            "[60247 rows x 2 columns]\n",
            "min_token_volume: 1\n",
            "max_token_volume: 685\n",
            "\n",
            "0th percentile of token_vol_no_stop: 1.0\n",
            "10th percentile of token_vol_no_stop: 18.0\n",
            "20th percentile of token_vol_no_stop: 25.0\n",
            "30th percentile of token_vol_no_stop: 32.0\n",
            "40th percentile of token_vol_no_stop: 39.0\n",
            "50th percentile of token_vol_no_stop: 49.0\n",
            "60th percentile of token_vol_no_stop: 60.0\n",
            "70th percentile of token_vol_no_stop: 76.0\n",
            "80th percentile of token_vol_no_stop: 100.0\n",
            "90th percentile of token_vol_no_stop: 144.0\n",
            "100th percentile of token_vol_no_stop: 685.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTkhr6ocDDR4"
      },
      "source": [
        "# https://www.codegrepper.com/code-examples/python/find+the+index+of+closest+element+above+and+below+a+value+in+an+array+python\n",
        "def find_nearest(array, value):\n",
        "    array = np.asarray(array)\n",
        "    idx = (np.abs(array - value)).argmin()\n",
        "    return array[idx]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYpp7-F1vxe-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "0525afd6-9e79-4bf7-958b-98658db3f71b"
      },
      "source": [
        "# POS tagging + various scoring mechanisms\n",
        "\n",
        "keywords = set(['service', 'staff', 'waiter', 'waitress', '$', 'price', 'prices', 'cost', 'overpriced', 'expensive', 'cheap', 'inexpensive', 'pricey', 'pricy', 'deal', 'deals', 'specials', 'special', 'pay', 'paid', 'inexpensive', 'location', 'located', 'area', 'neighborhood', 'selection', 'atmosphere', 'lighting', 'experience', 'experienced', 'toilet', 'washroom', 'bathroom', 'crowd', 'crowded', 'wait', 'waited', 'waiting', 'appointment'])\n",
        "optimal_token_vol_per = 80\n",
        "norm_div = 1\n",
        "adj_vol_weight = 0.3\n",
        "\n",
        "tokens['token_volume_score'] = tokens['token_vol_no_stop'].apply(lambda x: 1 - abs(token_volume_per.index(find_nearest(token_volume_per, x)) - optimal_token_vol_per)/max(optimal_token_vol_per - 0, 100 - optimal_token_vol_per))\n",
        "tokens['keyword_score_raw'] = tokens['tokenized_minus_stop'].apply(lambda x: len(set([tokens for tokens in x if tokens in keywords]))*norm_div/len(keywords))\n",
        "tokens['nouns_minus_stop'] = tokens['tokenized_minus_stop'].apply(lambda x: [(tokens, tags) for tokens, tags in nltk.pos_tag(x) if tags.startswith('N')])\n",
        "tokens['adj_minus_stop'] = tokens['tokenized_minus_stop'].apply(lambda x: [(tokens, tags) for tokens, tags in nltk.pos_tag(x) if tags.startswith('J')])\n",
        "tokens['adj_volume'] = tokens['adj_minus_stop'].apply(lambda x: len(x))\n",
        "\n",
        "min_adj_volume = min(tokens['adj_volume'])\n",
        "max_adj_volume = max(tokens['adj_volume'])\n",
        "tokens['adj_volume_score'] = tokens['adj_volume'].apply(lambda x: (x - min_adj_volume)/(max_adj_volume - min_adj_volume))\n",
        "\n",
        "min_keyword_score = min(tokens['keyword_score_raw'])\n",
        "max_keyword_score = max(tokens['keyword_score_raw'])\n",
        "tokens['keyword_score_norm'] = tokens['keyword_score_raw'].apply(lambda x: (x - min_keyword_score)/(max_keyword_score - min_keyword_score))\n",
        "\n",
        "tokens['volume_score'] = tokens['adj_volume_score']*adj_vol_weight + tokens['token_volume_score']*(1 - adj_vol_weight)\n",
        "\n",
        "token_volume_score_per = [np.percentile(tokens['token_volume_score'], 0), np.percentile(tokens['token_volume_score'], 20), np.percentile(tokens['token_volume_score'], 40), np.percentile(tokens['token_volume_score'], 60), np.percentile(tokens['token_volume_score'], 80), np.percentile(tokens['token_volume_score'], 100)]\n",
        "print(token_volume_score_per)\n",
        "print('min_adj_volume:', min_adj_volume)\n",
        "print('max_adj_volume:', max_adj_volume)\n",
        "\n",
        "tokens"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.25, 0.5, 0.75, 0.875, 1.0]\n",
            "min_adj_volume: 0\n",
            "max_adj_volume: 117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokenized_minus_stop</th>\n",
              "      <th>token_vol_no_stop</th>\n",
              "      <th>token_volume_score</th>\n",
              "      <th>keyword_score_raw</th>\n",
              "      <th>nouns_minus_stop</th>\n",
              "      <th>adj_minus_stop</th>\n",
              "      <th>adj_volume</th>\n",
              "      <th>adj_volume_score</th>\n",
              "      <th>keyword_score_norm</th>\n",
              "      <th>volume_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[first, time, visit, truly, amazing, ., every,...</td>\n",
              "      <td>26</td>\n",
              "      <td>0.2625</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>[(time, NN), (visit, NN), (plate, NN), (wonder...</td>\n",
              "      <td>[(first, JJ), (amazing, JJ), (single, JJ), (gr...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.051282</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.199135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[favorite, restaurant, pittsburgh, ,, anywhere...</td>\n",
              "      <td>77</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>[(restaurant, NN), (pittsburgh, NN), (aspect, ...</td>\n",
              "      <td>[(favorite, JJ), (eaten, JJ), (spent, JJ), (sa...</td>\n",
              "      <td>12</td>\n",
              "      <td>0.102564</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.643269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[service, lovely, ., live, nyc, eaten, spanish...</td>\n",
              "      <td>64</td>\n",
              "      <td>0.7875</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>[(service, NN), (nyc, NN), (style, NN), (tapas...</td>\n",
              "      <td>[(live, JJ), (eaten, JJ), (spanish, JJ), (good...</td>\n",
              "      <td>9</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.574327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[great, food, even, better, atmosphere, ., try...</td>\n",
              "      <td>17</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>[(food, NN), (item, NN), (section, NN), (split...</td>\n",
              "      <td>[(great, JJ), (least, JJS), (chicken, JJ)]</td>\n",
              "      <td>3</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.077692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[absolute, fantastic, dinner, !, !, partner, c...</td>\n",
              "      <td>203</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>[(dinner, NN), (partner, NN), (evening, NN), (...</td>\n",
              "      <td>[(absolute, JJ), (fantastic, JJ), (thursday, J...</td>\n",
              "      <td>34</td>\n",
              "      <td>0.290598</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.647179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60242</th>\n",
              "      <td>['m, chinatown, area, often, many, restaurants...</td>\n",
              "      <td>104</td>\n",
              "      <td>0.9875</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>[(area, NN), (restaurants, NNS), (place, NN), ...</td>\n",
              "      <td>[(chinatown, JJ), (many, JJ), (good, JJ), (mam...</td>\n",
              "      <td>22</td>\n",
              "      <td>0.188034</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.747660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60243</th>\n",
              "      <td>[location, :, las, vegas, chinatown, (, jones,...</td>\n",
              "      <td>54</td>\n",
              "      <td>0.6875</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>[(location, NN), (las, NN), (vegas, NNS), (jon...</td>\n",
              "      <td>[(dinner, JJ), (homemade, JJ), (flavorful, JJ)...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.051282</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.496635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60244</th>\n",
              "      <td>[place, upscale, feeling, chinese, food, joint...</td>\n",
              "      <td>46</td>\n",
              "      <td>0.5875</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>[(place, NN), (food, NN), (joint, NN), (dumpli...</td>\n",
              "      <td>[(upscale, JJ), (chinese, JJ), (soup, JJ), (la...</td>\n",
              "      <td>11</td>\n",
              "      <td>0.094017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.439455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60245</th>\n",
              "      <td>[coming, since, mamajias, ., ummmm, sure, 4.5,...</td>\n",
              "      <td>72</td>\n",
              "      <td>0.8375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>[(mamajias, NN), (stars, NNS), (ownership, NN)...</td>\n",
              "      <td>[(ummmm, JJ), (sure, JJ), (similar, JJ), (cold...</td>\n",
              "      <td>12</td>\n",
              "      <td>0.102564</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.617019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60246</th>\n",
              "      <td>[amazing, chinese, restaurant, !, 've, needing...</td>\n",
              "      <td>97</td>\n",
              "      <td>0.9875</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>[(restaurant, NN), (check, NN), (food, NN), (s...</td>\n",
              "      <td>[(chinese, JJ), (chinese, JJ), (gold, JJ), (co...</td>\n",
              "      <td>22</td>\n",
              "      <td>0.188034</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.747660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60247 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    tokenized_minus_stop  ...  volume_score\n",
              "0      [first, time, visit, truly, amazing, ., every,...  ...      0.199135\n",
              "1      [favorite, restaurant, pittsburgh, ,, anywhere...  ...      0.643269\n",
              "2      [service, lovely, ., live, nyc, eaten, spanish...  ...      0.574327\n",
              "3      [great, food, even, better, atmosphere, ., try...  ...      0.077692\n",
              "4      [absolute, fantastic, dinner, !, !, partner, c...  ...      0.647179\n",
              "...                                                  ...  ...           ...\n",
              "60242  ['m, chinatown, area, often, many, restaurants...  ...      0.747660\n",
              "60243  [location, :, las, vegas, chinatown, (, jones,...  ...      0.496635\n",
              "60244  [place, upscale, feeling, chinese, food, joint...  ...      0.439455\n",
              "60245  [coming, since, mamajias, ., ummmm, sure, 4.5,...  ...      0.617019\n",
              "60246  [amazing, chinese, restaurant, !, 've, needing...  ...      0.747660\n",
              "\n",
              "[60247 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylqicpacK1xF",
        "outputId": "18f6c6ad-b7c1-4df9-d1df-5ac547bc42f4"
      },
      "source": [
        "# print a particular record to observe various scores\n",
        "\n",
        "print('tokenized_minus_stop:', tokens.iloc[16608]['tokenized_minus_stop'])\n",
        "print()\n",
        "\n",
        "print('token_vol_no_stop:', tokens.iloc[16608]['token_vol_no_stop'])\n",
        "print('token_volume_score:', tokens.iloc[16608]['token_volume_score'])\n",
        "print()\n",
        "\n",
        "print('adj_volume:', tokens.iloc[16608]['adj_volume'])\n",
        "print('adj_volume_score:', tokens.iloc[16608]['adj_volume_score'])\n",
        "print()\n",
        "\n",
        "print('volume_score:', tokens.iloc[16608]['volume_score'])\n",
        "print()\n",
        "\n",
        "print('keyword_score_raw:', tokens.iloc[16608]['keyword_score_raw'])\n",
        "print('keyword_score_norm:', tokens.iloc[16608]['keyword_score_norm'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenized_minus_stop: ['stopped', 'last', 'week', 'conclude', 'graduation', 'celebration', '.', 'place', 'decided', 'upon', ',', 'little', 'skeptical', 'huge', 'fan', 'hookah', 'around', 'smoke', ',', 'went', 'anyway', '.', 'arrived', 'notified', 'show', 'live', 'bands', 'belly', 'dancers', '.', 'cost', '$', '10', '.', 'got', 'drink', '.', 'none', 'us', 'wanted', 'pay', 'due', 'time', '.', 'luckily', ',', 'space', 'available', \"n't\", 'pay', 'kind', 'enough', 'seat', 'large', 'party', '.', 'place', 'pretty', 'big', 'separate', 'rooms', '.', \"n't\", 'able', 'go', 'big', 'room', ',', 'due', 'event', ',', 'take', 'peek', 'saw', ',', 'seemed', 'big', 'colorful', '.', 'low', 'lighting', 'sets', 'chill', 'atmosphere', '.', 'plan', 'spend', 'money', ',', \"n't\", 'happen', '.', 'looked', 'menu', 'said', ',', '``', 'ohh', ',', 'looks', 'good', '...', '!', \"''\", 'plan', 'spending', 'money', 'went', 'smoke', 'hookah', '.', 'ordered', 'olive', 'mediterranean', 'combo', 'came', 'hummus', ',', 'baba', 'ganoush', ',', 'feta', 'cheese', ',', 'cucumber', ',', 'yogurt', 'salad', ',', 'tomatoes', ',', 'olives', 'tabouleh', 'along', '2', 'orders', 'fries', '.', ',', 'went', 'town', 'combo', '!', 'serve', 'warm', 'pita', 'bread', 'ca', \"n't\", 'tell', 'many', 'ate', '.', 'one', 'minis', \"n't\", 'agree', 'taste', 'buds', '.', 'combo', 'awesome', 'ca', \"n't\", 'beat', 'price', 'either', 'food', '.', 'lady', 'helping', 'us', 'said', 'one', 'liveliest', 'groups', \"'s\", 'loved', 'us', '.', 'loved', 'service', 'excellent', '!', 'co-workers', 'checked', 'see', '.', 'checked', 'hookahs', 'others', 'needed', 'anything', ',', 'made', 'happen', '.', 'prompt', ',', 'friendly', 'service', '.', 'evening', 'enjoyable', 'great', 'way', 'end', 'night', 'celebration', '.']\n",
            "\n",
            "token_vol_no_stop: 210\n",
            "token_volume_score: 0.8\n",
            "\n",
            "adj_volume: 31\n",
            "adj_volume_score: 0.26495726495726496\n",
            "\n",
            "volume_score: 0.6394871794871795\n",
            "\n",
            "keyword_score_raw: 0.18421052631578946\n",
            "keyword_score_norm: 0.5833333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAeFyKY6tuTD"
      },
      "source": [
        "tokens.to_csv('tokens.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "BogCZpxh3fLI",
        "outputId": "734bb2dd-1e88-49b5-c0b0-d7b51e336089"
      },
      "source": [
        "# get a subset of tokens dataframe based on whether normalized keyword score is 0 and and volume score is >= 0.5\n",
        "\n",
        "tokens_subset = tokens.loc[(tokens['keyword_score_norm'] == 0) & (tokens['volume_score'] >= 0.5)]\n",
        "\n",
        "tokens_subset"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokenized_minus_stop</th>\n",
              "      <th>token_vol_no_stop</th>\n",
              "      <th>token_volume_score</th>\n",
              "      <th>keyword_score_raw</th>\n",
              "      <th>nouns_minus_stop</th>\n",
              "      <th>adj_minus_stop</th>\n",
              "      <th>adj_volume</th>\n",
              "      <th>adj_volume_score</th>\n",
              "      <th>keyword_score_norm</th>\n",
              "      <th>volume_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[5, stars, ., best, restaurant, pittsburgh, ,,...</td>\n",
              "      <td>120</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[(stars, NNS), (restaurant, NN), (pittsburgh, ...</td>\n",
              "      <td>[(humble, JJ), (studied, JJ), (spanish, JJ), (...</td>\n",
              "      <td>14</td>\n",
              "      <td>0.119658</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.692147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[outstanding, ., maybe, best, meal, 've, ever,...</td>\n",
              "      <td>79</td>\n",
              "      <td>0.8875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[(meal, NN), (order, NN), (oxtail, NN), (serra...</td>\n",
              "      <td>[(outstanding, JJ), (best, JJS), (much, JJ), (...</td>\n",
              "      <td>9</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.644327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>['m, love, morcilla, !, although, unfortunatel...</td>\n",
              "      <td>64</td>\n",
              "      <td>0.7875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[(morcilla, NN), (drinks, NNS), (morcilla, NN)...</td>\n",
              "      <td>[(love, JJ), (unfortunately, JJ), (fabulous, J...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.059829</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.569199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[going, focus, negative, think, could, 5, star...</td>\n",
              "      <td>156</td>\n",
              "      <td>0.8500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[(think, NN), (place, NN), (suoerlative, NN), ...</td>\n",
              "      <td>[(negative, JJ), (star, JJ), (better, JJR), (w...</td>\n",
              "      <td>29</td>\n",
              "      <td>0.247863</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.669359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>['m, state, customer, chose, restaurant, dinne...</td>\n",
              "      <td>63</td>\n",
              "      <td>0.7750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[(state, NN), (customer, NN), (dinner, NN), (p...</td>\n",
              "      <td>[(restaurant, JJ), (less, JJR), (intense, JJ),...</td>\n",
              "      <td>8</td>\n",
              "      <td>0.068376</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.563013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60207</th>\n",
              "      <td>[came, ces, upon, recommendation, friend, ., g...</td>\n",
              "      <td>59</td>\n",
              "      <td>0.7375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[(ces, NNS), (recommendation, NN), (friend, NN...</td>\n",
              "      <td>[(good, JJ), (next, JJ), (good, JJ), (nice, JJ...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.085470</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.541891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60214</th>\n",
              "      <td>[great, food, !, 's, wan, na, say, ., opinion,...</td>\n",
              "      <td>60</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[(food, NN), (na, NNS), (opinion, NN), (food, ...</td>\n",
              "      <td>[(great, JJ), (wan, JJ), (open, JJ), (great, J...</td>\n",
              "      <td>12</td>\n",
              "      <td>0.102564</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.555769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60218</th>\n",
              "      <td>[give, two, stars, ,, things, edible, ..., sup...</td>\n",
              "      <td>106</td>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[(stars, NNS), (things, NNS), (super, NN), (or...</td>\n",
              "      <td>[(decided, JJ), (chinese, JJ), (disappointed, ...</td>\n",
              "      <td>21</td>\n",
              "      <td>0.179487</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.736346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60239</th>\n",
              "      <td>[save, room, freshly, baked, egg, tarts, !, !,...</td>\n",
              "      <td>90</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[(room, NN), (egg, NN), (tarts, NNS), (week, N...</td>\n",
              "      <td>[(good, JJ), (pepper, JJ), (good, JJ), (repeat...</td>\n",
              "      <td>11</td>\n",
              "      <td>0.094017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.693205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60245</th>\n",
              "      <td>[coming, since, mamajias, ., ummmm, sure, 4.5,...</td>\n",
              "      <td>72</td>\n",
              "      <td>0.8375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[(mamajias, NN), (stars, NNS), (ownership, NN)...</td>\n",
              "      <td>[(ummmm, JJ), (sure, JJ), (similar, JJ), (cold...</td>\n",
              "      <td>12</td>\n",
              "      <td>0.102564</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.617019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3598 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    tokenized_minus_stop  ...  volume_score\n",
              "5      [5, stars, ., best, restaurant, pittsburgh, ,,...  ...      0.692147\n",
              "32     [outstanding, ., maybe, best, meal, 've, ever,...  ...      0.644327\n",
              "35     ['m, love, morcilla, !, although, unfortunatel...  ...      0.569199\n",
              "43     [going, focus, negative, think, could, 5, star...  ...      0.669359\n",
              "51     ['m, state, customer, chose, restaurant, dinne...  ...      0.563013\n",
              "...                                                  ...  ...           ...\n",
              "60207  [came, ces, upon, recommendation, friend, ., g...  ...      0.541891\n",
              "60214  [great, food, !, 's, wan, na, say, ., opinion,...  ...      0.555769\n",
              "60218  [give, two, stars, ,, things, edible, ..., sup...  ...      0.736346\n",
              "60239  [save, room, freshly, baked, egg, tarts, !, !,...  ...      0.693205\n",
              "60245  [coming, since, mamajias, ., ummmm, sure, 4.5,...  ...      0.617019\n",
              "\n",
              "[3598 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}